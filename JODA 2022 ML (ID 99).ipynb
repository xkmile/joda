{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Luentopäiväkirjat\n",
    "\n",
    "## Hieman minusta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Luento 1\n",
    "\n",
    "## Osallistuminen ja lähteet\n",
    "Osallistuin luentoon ja demoon keväällä 2021, mutten kyselysessioon. Luin luento-notebookin. Asensin Anacondan Windowsille ilman ohjeita. Mietiskelin miten tutkisisin aineistoani - projektin toimitusdataa. Kohosen kartta houkuttaisi erilaisten projektien luokitteluun, luin aiheesta https://medium.com/@dalicodes/overview-of-self-organizing-maps-som-with-its-python-implementation-in-determining-safe-airlines-db8f6018a2b. Akuuttia oli saada yhteys tietokantaan, siihen löysin esimerkin https://medium.com/@devartimahakalkar/connecting-sql-datasets-with-pandas-105f8eb68f1a. Tutkin saatavilla olevaa aineistoa ja piirtelin E/R-kaaviota asioiden suhteista.\n",
    "\n",
    "## Keskeiset asiat\n",
    "Datan määrä lisääntyy. On muotoutunut opinala ja ammattikunta, jotka keskittyvät suurien tietomäärien analysointiin ja näistä analyyseista saatavan tiedon soveltamiseen toiminnan kehittämisessä. Datan työstämiseen on eri keinoja, mm. koneoppimisen tai tilastollisen analyysin työkalut. Kurssilla opetetaan koodiperusteista lähestymistapaa, koska koodi:\n",
    "a) on läpinäkyvää; \n",
    "b) siihen voi liittää versionhallinnan; \n",
    "c) sille on paljon yhteisötukea; \n",
    "d) palasina koodi on uudelleenkäytettävää\n",
    "\n",
    "Jupyter on näppärä ympäristö, siinä voi yhdistää koodin ja dokumentaation notebook-muotoon. Koodia voi ajaa paloissa. Koodiprojektiin on helppo tuoda valmiita kirjastoja. Pythonilla ja Pandas-kirjastolla voi nopeasti käsitellä dataa ja jatkojalostaa sitä paremmin analysoitavaan muotoon. Kirjastoja on lisäksi esim. kuvantamiseen.\n",
    "\n",
    "Datatieteilijällä on skillsejä kommunikaatiossa, tilastotieteissä, ohjelmoinnissa ja liiketoiminnassa. Kun löytyy taitoja kaikista, on täydellinen. Erilaisia osaamisen osa-alueita esim. metrokartassa jaoiteltu toisin ja niitä on monia ja näihin liittyviä työkaluja (softia, menetelmiä, jne.) vielä enemmän.\n",
    "\n",
    "CRISP-DM kuvailee tietämyksen luonnin vaiheita, kun saatavilla on jotain dataa. Vaatimuksia ovat jonkin dataan liiketoimintaongelman ymmärtäminen, datan haltuunotto, mallintaminen, arviointi ja tätä kautta ongelman ymmärtäminen yhä paremmin. Tietämyksen lisääntyminen on syklistä tässä. \n",
    "\n",
    "\n",
    "## Oivallukset\n",
    "1. Datatieteily vaikuttaa mahdottoman mielenkiintoiselta\n",
    "2. Mitä ollaan tekemässä -> liiketoimintaongelmien parempi ymmärrys datasta jalostetulla tietämyksellä\n",
    "3. Mahtaako täydellisen datatieteilijän työ skaalautua. Jos osaat kaiken itse, voit tehdä kaiken - asiakkaan kanssa tehtävästä ongelmanmuodostuksesta datan putsaamisen kautta toteutukseen ja analyysiin. Todella hyvää asiakaspalvelua ja tehokasta tekemistä, kun tiedonvaihtoon ei mene aikaa. Mutta jossain vaiheessa yhden konsultin tunnit kalenterista loppuvat ja työtä joutuu jakamaan ja ihmiset erikoistuvat. The Data Scientist Veen Diagram näyttää tässä valossa enemmän ostoslistalta, kun kootaan tiimiä.\n",
    "4. Koodipohjainen lähestymistapa lienee fiksumpi kuin aiemmin soveltamani graafiset työkalut. Ymmärrän toistettavuuden ja versionhallinnan arvon.\n",
    "5. Erinäisten funktioiden soveltaminen dataan .apply()-metodilla näyttää hemmetin näppärältä. Aiemmin olisin tehnyt vastaavia SQL:ssä.\n",
    "\n",
    "\n",
    "## Tuunaukset\n",
    "1. Chat sittenkin piiloon ja kysymysten läpikäynti sopivissa välein? --> Voi kysyä chatissa kysymyksensä ilman, että keskeyttää luennon.\n",
    "2. Omaa stressiäni olisi vähentänyt, jos luennoitsija olisi kertonut etukäteen, mistä aikoo luennoida. Välillä ADHD-aivoni juoksivat muutaman askeleen edellä ja teki mieli kysellä tarkentavia asioista, jotka olivat vain myöhempänä listalla. Jos lista opittavista asioista olisi ollut etukäteen tiedossa -> ei tarvitse jännittää, opinko kohta haluamani asian vai unohdanko sen.\n",
    "\n",
    "## Koodi\n",
    "Sain yhteyden pyodbc:n kanssa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "\n",
    "# connect and query database to build dataframe\n",
    "DB = {'servername': 'localhost\\SQLSERVER2019',\n",
    "      'database': 'Project Deliveries',\n",
    "      'uid': '',\n",
    "      'pwd': ''}\n",
    "\n",
    "QUERY = 'SELECT TOP (1000) * FROM [Project Deliveries].[dbo].[Analysis Data View] WHERE [Delivery Item type] is not null'\n",
    "\n",
    "conn = pyodbc.connect('DRIVER={SQL Server};SERVER=' + DB['servername'] + ';DATABASE=' + DB['database'] + ';Trusted_Connection=Yes')\n",
    "#conn = pyodbc.connect('DRIVER={SQL Server};SERVER=' + DB['servername'] + ';DATABASE=' + DB['database'] + ';uid=' + DB['uid'] + ';pwd=' + DB['pwd'] + \";Trusted_Connection=Yes\")\n",
    "df = pd.read_sql_query(QUERY, conn)\n",
    "\n",
    "print('Connected. Queried.')\n",
    "\n",
    "# test that we have data\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Luento 2\n",
    "\n",
    "## Osallistuminen ja lähteet\n",
    "Osallistuin puoleen luentoon keväällä 2021. Demon katsoin vähän puolella silmällä, datan raapiminen ei suoraan sanoen hirveästi kiinnosta lähteenä. Olen sitä tehnyt alkeellisimmilla työkaluilla ja oli kiva nähdä, miten ne olivat kehittyneet. Harjoituksen osalta keskityin muokkaamaan toimitusdatastani aikasarjoja.\n",
    "\n",
    "## Keskeiset asiat\n",
    "Guon työnkulku esittelee datatieteen prosessia. 80% ajasta voi varata datan valmisteluun, Jos data on alunperin suunniteltu analytiikkaa varten, aikaa menee tietenkin suhteessa paljon vähemmän. Mitä tuotteistetumpi tai paketoidumpi analyysi, sitä vähemmän aikaa kuluu. Tieteellisessä työssä pyritään pikemminkin laajentamaan tuotteistuksen rajoja ja käytetty aika on suurempi.\n",
    "\n",
    "Valmistelua seuraa reflektio, tiedon luonti, kokoustelu. Huomataan, että alkuperäinen kysymys on harvoin lopullinen, kun keskustelujen ja ajatusten edetessa löydetään mielenkiintoisempia ja parempia kysymyksiä ja aineistoja. Kun on disseminaation vuoro, tässä on pari eri vaihtoehtoa: joko uusi tieto voi vaikuttaa toimintatapoihin tai toisena ääripäänä datakoneistosta tulee työkalu, jota käytetään jatkuvasti. \n",
    "\n",
    "Business intelligencen puolella puhutaan yleisesti ETL-prosessista: extract, transform and load. Data on lähteessä, josta se otetaan, muunnetaan sovellettavaan muotoon ja ladataan raportoinnin tietovarastoon. Tavoitteena on rakentaa monikäyttöinen tietovarasto, jota käytetään raporteissa ja josta on helppo hakea tietoa eri käyttötarkoituksia varten. Tiedon hyödyntäminen on hyvin tuotteistettua. Kyseessä on vakiintunut toimiala. Datatieteen puolella vastaava prosessi on DAD: discover, access ja distill. Periaate on sama kuin BI:ssä - mutta tempo on nopeampi. Tarkoitus on tehdä analyysi päivän sisällä alusta loppuun.\n",
    "\n",
    "## Oivallukset\n",
    "1. Raavinta näyttää nykyään helpolta, Scrapy on kypsän oloinen työkalu. Itse latasin aikoinaan kauden 2008-2009 NHL play-by-play -tilastot netistä web spiderilla, muunsin ne XHTML-muotoon jollain komentojonokäsittelyllä, käänsin yksittäiset pelit tilastoineen sopivaan XML-muotoon XSLT-transformaatiolla ja tämän jälkeen latasin datan tietokantaan. Nykynuoret pääsevät niin helpolla.\n",
    "2. ETL on töistä tuttua. Ajatus DAD:sta päivän sisällä tehtävänä on innostava, sillä tiedon logistiikka on usein raskain osuus.\n",
    "3. Itse olin jopa yllättynyt, kuinka suuri osa yrityksistä käyttäisi nykyaikaisia työkaluja tai omaa data-analytiikkatiimin.\n",
    "4. \n",
    "5. \n",
    "\n",
    "## Tuunaukset\n",
    "\n",
    "\n",
    "## Koodi\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Luento 4\n",
    "https://colab.research.google.com/github/TeemuMikkonen/JODA-NLP/blob/main/Solita_JODA.ipynb\n",
    "\n",
    "Teemun vertailu \"kolikonheittoon\" - ts. naivi algoritmi. Miten voisi soveltaa omaan työhön?\n",
    "\n",
    "NLP on luonnollisen - ei rakenteellisen - kielen käsittelyä. Rakenteettomuus on se haaste, normaalisti koneoppiminen vaatii numeraalista dataa. Esikäsittely ja piirteiden käsittely tulee tässä esille. Näkyvin sovellus on chat-bot - nämä pystyvät hoitamaan selvimpiä tapauksia. Konekäännökset on toinen juttu. Tekstimassojen luokittelu ja metatiedottaminen (ohjattua, luokat valmiina). Korpus = iso tekstimassa. Tekstimassojen teemojen etsiminen (ohjaamaton oppiminen, luokkien etsintää (tarkenna)). LDA! Hot topic! LSI!\n",
    "\n",
    "https://data.solita.fi/finnish-stemming-and-lemmatization-in-python/\n",
    "\n",
    "Stop word -listat ovat kontekstiriippuvaisia - pitää miettiä projekteittain. \n",
    "\n",
    "Naivi malli olisi ottaa yleisin kategoria.\n",
    "\n",
    "Yliotanta - luodaan ylimääräisiä datapisteitä. NLP:ssä hankalaa...\n",
    "\n",
    "Aliotanta - vähennetään datapisteitä yliedustetuista kategorioista. Heikentää oppimista, ei suositeltavaa.\n",
    "\n",
    "Prosessikuva; Esikäsittely, piirteiden erottaminen, ulottuvuuksien vähentäminen, \n",
    "\n",
    "--\n",
    "\n",
    "Perusmuotoistaminen: vähennetään erilaisia samoja, tulkitaan samoiksi\n",
    "\n",
    "Stemmaus: mikä olikaan ero?\n",
    "\n",
    "--\n",
    "\n",
    "Teemu lisää dataan uusia sarakkeita ja näkee miten esikäsittely siihen vaikuttaa.\n",
    "\n",
    "--\n",
    "\n",
    "PCA - principal component analysis. Unsupervised learning, i.e. the system decides what to deduce from the data without having a goal value. Many models gets slower when attributes or dimensions increase to hundreds, PCA makes sense, because it reduces dimensions. How much of variance each dimension explain\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
